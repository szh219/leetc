### 实习准备

CV岗  了解一下目标识别， 目标检测算法，分类， 语义分割的基本内容

找CV岗位的八股文，卷积那些东西

自己简历上的东西 比如论文： Weighted Guass， DPSH的内容  怎么加的attention 链接https://lilianweng.github.io/posts/2018-06-24-attention/ 怎样用在ImageNet数据集上的， 使用方法是啥 确定下来， 参考dpsh的内容

简历上的东西 thermal GAN怎么用的 这些都弄清



怎样识别银行卡号码

### 一些问题：

:1.卷积核卷积的物理意义，2.Iou计算3.常见的深度学须评价指标4.网络对比（不同的分类网络，不同的目标检测网络）5.梯度消失爆炸问题6.感受野 7. 过拟合，欠拟合8.反向传播的问题9.softmax的求导10.常见的损失函数，项目中网络用到的损失函数 11.Bn，dropout的原理细节12.图像处理的知识，比如各种算子，高斯模糊. 过拟合欠拟合



weighted guass: 相关模型：CNNH HashNet, DCH,  

权重机制怎么加的

BatchNorm: 用在激活函数前，加快收敛，更稳定。都是让该层参数稳定下来，CV里BatchNorm 更有效，不同特征之间的大小关系无了，但保留不同样本之间的大小关系 ， 特征依赖不同样本之间统计





目标检测

RCNN 方法 finetune 微调 怎么微调





项目经历可能的问题：



简单GAN： https://github.com/devnag/pytorch-generative-adversarial-networks/blob/master/gan_pytorch.py

损失函数用log的形式

课设：Pix2Pix 模型结构 G G*G*为**Generator**由神经网络自动生成的、假的图片 G ( z ) G(z) 公式

Pix2Pix 不再输入随机噪声而是 adam 优化器



GAN 的模式塌陷问题 Wasserstein距离  GAN 怎么调参数的

GAN 损失函数https://zhuanlan.zhihu.com/p/72195907![截屏2022-03-20 上午10.58.53](../Library/Application Support/typora-user-images/截屏2022-03-20 上午10.58.53.png)

遇到GAN训练不稳定问题。通过Wasserstein GAN来解决这个问题。WGAN前作分析了Ian Goodfellow提出的原始GAN两种形式各自的问题，第一种形式等价在最优判别器下等价于最小化生成分布与真实分布之间的JS散度，由于随机生成分布很难与真实分布有不可忽略的重叠以及JS散度的突变特性，使得生成器面临梯度消失的问题；第二种形式在最优判别器下等价于既要最小化生成分布与真实分布直接的KL散度，又要最大化其JS散度，相互矛盾，导致梯度不稳定，而且KL散度的不对称性使得生成器宁可丧失多样性也不愿丧失准确性，导致collapse mode现象。 

WGAN前作针对分布重叠问题提出了一个过渡解决方案，通过对生成样本和真实样本加噪声使得两个分布产生重叠，理论上可以解决训练不稳定的问题，可以放心训练判别器到接近最优，但是未能提供一个指示训练进程的可靠指标，也未做实验验证。 

WGAN本作引入了Wasserstein距离，由于它相对KL散度与JS散度具有优越的平滑特性，理论上可以解决梯度消失问题。接着通过数学变换将Wasserstein距离写成可求解的形式，利用一个参数数值范围受限的判别器神经网络来最大化这个形式，就可以近似Wasserstein距离。在此近似最优判别器下优化生成器使得Wasserstein距离缩小，就能有效拉近生成分布与真实分布。WGAN既解决了训练不稳定的问题，也提供了一个可靠的训练进程指标，而且该指标确实与生成样本的质量高度相关。



Pix2Pix 图像的翻译过程，映射, 注意损失函数的不同

![image-20220320104735929](../Library/Application Support/typora-user-images/image-20220320104735929.png)

![截屏2022-03-16 下午2.04.19](../Library/Application Support/typora-user-images/截屏2022-03-16 下午2.04.19.png)styleGAN z(gaussian)->w(任意) adain 图像风格上很好用， mapping network f 就是多个全链接层，加入了训练集有偏的问题

CycleGAN 不使用成对图片   自动保持内容但风格处理上问题 源代码：https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix/blob/master/models/cycle_gan_model.py

![截屏2022-03-16 下午2.43.05](../Library/Application Support/typora-user-images/截屏2022-03-16 下午2.43.05.png)

cycle GAN引入循环一直损失

gan 代码解读： 

https://blog.csdn.net/jiongnima/article/details/80033169

为什么使用pix2pix =： 更好理解，结构兼容thermalGAN 效果好速度快，不会过度的风格化

为什么不用Pix2PixHD这样的

为什么GAN不好训练

损失函数用的BCElogitloss



语义分割部分：https://blog.csdn.net/Datawhale/article/details/121724424 常用数据集VOC



迁移学习部分：

利用数据、任务和模型之间的相似性将旧领域中的模型应用于新领域中，其关键在于找到新任务与旧任务之间的相似点。图像分类任务。 基于样本的迁移学习，基于特征的迁移学习，基于模型的迁移学习和基于关系的迁移学习

请描述生成对抗网络GAN、Loss函数、难训练的原因？



cross entropy 实现和计算方式

Weighted Gaussian 部分： 语训练 vgg16 pretrained  alexnet pretrained, 最后激活函数修改为tanh





GNN 部分

模型的评估指标和适用场景  基础知识![截屏2022-03-21 上午11.12.23](../Library/Application Support/typora-user-images/截屏2022-03-21 上午11.12.23.png)





## ML岗可能的问题

![截屏2022-03-17 下午5.18.59](../Library/Application Support/typora-user-images/截屏2022-03-17 下午5.18.59.png)

BOOSTING 迭代学习 关注错误

二分类交叉熵![image-20220321094858878](../Library/Application Support/typora-user-images/image-20220321094858878.png)



GBDT https://www.bilibili.com/video/BV1Bt411j7KH/?spm_id_from=333.788.recommend_more_video.7

GBDT关键损失函数负梯度作为残差取更新， 依赖， 不断逼近拟合



https://blog.csdn.net/qq_40035462/article/details/123305990 损失函数大全

https://www.bilibili.com/read/cv11240716/  机器学习面试题

知乎上的https://zhuanlan.zhihu.com/p/41952330

【机器学习面试题汇总（1~50题）】https://minipro.baidu.com/ma/qrcode/parser?app_key=y1lpwNoOyVpW33XOPd72rzN4aUS43Y3O&launchid=ca43cc84-fb68-489c-937d-5bd5bbde4981&path=%2Fpages%2Fblog%2Findex%3FblogId%3D88636965%26_swebFromHost%3Dbaiduboxapp



https://blog.csdn.net/sinat_35512245/article/details/78796328

华为机试https://blog.nowcoder.net/stick/96850?page=1



## CV岗位可能的问题

https://ask.julyedu.com/detail/?id=98709 CV 面经问题总结

CV ： https://www.nowcoder.com/discuss/863989?type=all&order=recall&pos=&page=1&ncTraceId=&channel=-1&source_id=search_all_nctrack&gio_id=88CA296BBBAE951435ED703491A553E2-1648045713332

掌握C++面试基础 背C++ 八股文
